{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f71aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse, time, logging, os, sys, math\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluoncv as gcv\n",
    "from mxnet import gluon, nd, init, context\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.data.transforms import video\n",
    "from gluoncv.data import VideoClsCustom\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2cc838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 40 training samples.\n"
     ]
    }
   ],
   "source": [
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "per_device_batch_size = 5\n",
    "num_workers = 0\n",
    "batch_size = per_device_batch_size * num_gpus\n",
    "\n",
    "train_dataset = VideoClsCustom(root=r\"FrameStrip\",\n",
    "                               setting=r\"train.txt\",\n",
    "                               train=True,\n",
    "                               new_length=32,\n",
    "                               #video_loader=True,\n",
    "                               #use_decord=True,\n",
    "                               transform=transform_train)\n",
    "print('Load %d training samples.' % len(train_dataset))\n",
    "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a93d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2_weight is done with shape:  (64, 3, 5, 7, 7)\n",
      "batchnorm2_gamma is done with shape:  (64,)\n",
      "batchnorm2_beta is done with shape:  (64,)\n",
      "batchnorm2_running_mean is done with shape:  (64,)\n",
      "batchnorm2_running_var is done with shape:  (64,)\n",
      "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
      "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
      "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
      "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
      "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
      "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
      "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
      "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
      "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
      "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
      "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
      "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
      "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
      "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
      "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
      "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
      "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
      "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
      "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
      "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
      "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
      "dense2_weight is skipped with shape:  (101, 2048)\n",
      "dense2_bias is skipped with shape:  (101,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I3D_ResNetV1(\n",
      "  (first_stage): HybridSequential(\n",
      "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  )\n",
      "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  (res_layers): HybridSequential(\n",
      "    (0): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
      "  (head): HybridSequential(\n",
      "    (0): Dropout(p = 0.8, axes=())\n",
      "    (1): Dense(2048 -> 101, linear)\n",
      "  )\n",
      "  (fc): Dense(2048 -> 101, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = get_model(name='i3d_resnet50_v1_custom', nclass=101)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a99ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay = 0.1\n",
    "lr_decay_epoch = [40, 80, 100]\n",
    "optimizer = 'sgd'\n",
    "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144a63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef290f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metric = mx.metric.Accuracy()\n",
    "train_history = TrainingHistory(['training-acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ef9407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train=0.625000 loss=4.188960 time: 42.464804\n",
      "[Epoch 1] train=0.850000 loss=2.349616 time: 10.810051\n",
      "[Epoch 2] train=0.975000 loss=0.689237 time: 10.955666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3\n",
    "lr_decay_count = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_metric.reset()\n",
    "    train_loss = 0\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "\n",
    "        with ag.record():\n",
    "            output = []\n",
    "            for _, X in enumerate(data):\n",
    "                X = X.reshape((-1,) + X.shape[2:])\n",
    "                pred = net(X)\n",
    "                output.append(pred)\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
    "\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
    "        train_metric.update(label, output)\n",
    "\n",
    "        if i == 100:\n",
    "            break\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "\n",
    "    train_history.update([acc])\n",
    "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
    "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
    "\n",
    "train_history.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf37d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
